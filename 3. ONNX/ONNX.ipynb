{"cells":[{"cell_type":"markdown","source":["# Convert to ONNX\n"],"metadata":{"id":"tqqzyxJIhm1b"}},{"cell_type":"code","source":["# !pip install onnxruntime onnx transformers optimum"],"metadata":{"id":"rrLaTg2Mh-kY","executionInfo":{"status":"ok","timestamp":1689374844984,"user_tz":-420,"elapsed":9,"user":{"displayName":"23522009 Farrel Satya Putra Mahendra","userId":"05920376284151714449"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JI-0IENVilQx","executionInfo":{"status":"ok","timestamp":1689374847797,"user_tz":-420,"elapsed":2821,"user":{"displayName":"23522009 Farrel Satya Putra Mahendra","userId":"05920376284151714449"}},"outputId":"1a487b64-16b3-48ef-a023-abf10c66a80d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","from torch import optim\n","import torch.nn.functional as F\n","\n","from transformers import BertForSequenceClassification, BertConfig, BertTokenizer\n","\n","from pathlib import Path\n","import timeit\n","import onnxruntime as ort\n","from onnxruntime import InferenceSession\n","from optimum.onnxruntime import ORTModelForSequenceClassification"],"metadata":{"id":"kUiLrPA_iPBP","executionInfo":{"status":"ok","timestamp":1689374857755,"user_tz":-420,"elapsed":9969,"user":{"displayName":"23522009 Farrel Satya Putra Mahendra","userId":"05920376284151714449"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Converting a model to ONNX format is straightforward. We just have to instantiate the model with the `ORTModelForSequenceClassification` from_pretrained function."],"metadata":{"id":"mvOSPC1pl7q4"}},{"cell_type":"code","source":["# Create a PATH to save the model\n","model_onnx_path = Path(\"/content/drive/MyDrive/Models/indobert-onnx\")\n","\n","# Load the model converted to ORT (ONNX)\n","model_load_path = Path(\"/content/drive/MyDrive/Models/indobert\")\n","model_onnx = ORTModelForSequenceClassification.from_pretrained(model_load_path, export=True)\n","\n","# Save the model\n","model_onnx.save_pretrained(model_onnx_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jw8-4wqbiF_P","executionInfo":{"status":"ok","timestamp":1689374878613,"user_tz":-420,"elapsed":20893,"user":{"displayName":"23522009 Farrel Satya Putra Mahendra","userId":"05920376284151714449"}},"outputId":"9c4bb4ff-bb41-4ad6-b222-a5d0c0e01961"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["Framework not specified. Using pt to export to ONNX.\n","Using framework PyTorch: 2.0.1+cu118\n","Overriding 1 configuration item(s)\n","\t- use_cache -> False\n"]},{"output_type":"stream","name":"stdout","text":["============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n","verbose: False, log level: Level.ERROR\n","======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n","\n"]}]},{"cell_type":"markdown","source":["The inputs format for ONNX is a bit different than the usual. We have to declare it in a dictionary."],"metadata":{"id":"SgNsxmG7mdv8"}},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained(model_load_path)\n","\n","# Create inputs for the model\n","text = ['Bahagia hatiku melihat pernikahan putri sulungku yang cantik jelita']\n","inputs = tokenizer(text)\n","\n","inputs_onnx = dict(\n","    input_ids=np.array(inputs[\"input_ids\"]).astype(\"int64\"),\n","    attention_mask=np.array(inputs[\"attention_mask\"]).astype(\"int64\"),\n","    token_type_ids=np.array(inputs[\"token_type_ids\"]).astype(\"int64\")\n",")\n","\n","inputs_onnx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ICpeGM0BiLoY","executionInfo":{"status":"ok","timestamp":1689374878614,"user_tz":-420,"elapsed":20,"user":{"displayName":"23522009 Farrel Satya Putra Mahendra","userId":"05920376284151714449"}},"outputId":"21b446fa-9c0a-4d37-dd5e-f8eec5e5844c"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': array([[    2,  4771, 10413,   722,  3300,  3466, 19227,   457,    34,\n","          2176, 17377,   155,     3]]),\n"," 'attention_mask': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n"," 'token_type_ids': array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["Let's try to inference those inputs!"],"metadata":{"id":"40ZNBpznmsEJ"}},{"cell_type":"code","source":["# Create ONNX session to do inference\n","sess = InferenceSession(str(model_onnx_path / \"model.onnx\"), providers=[\"CPUExecutionProvider\"])"],"metadata":{"id":"JqRXFF5njRLC","executionInfo":{"status":"ok","timestamp":1689374880313,"user_tz":-420,"elapsed":360,"user":{"displayName":"23522009 Farrel Satya Putra Mahendra","userId":"05920376284151714449"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["i2w = {0: 'positive', 1: 'neutral', 2: 'negative'}\n","\n","# Do the inference\n","logits = sess.run(None, input_feed=inputs_onnx)[0]\n","label = torch.topk(torch.from_numpy(logits), k=1, dim=-1)[1].squeeze().item()\n","probability = F.softmax(torch.from_numpy(logits), dim=-1).squeeze()[label].item()\n","\n","print(f\"Label: {i2w[label]}\\nProbability: {probability}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pe7FZB9Yjc6y","executionInfo":{"status":"ok","timestamp":1689375192536,"user_tz":-420,"elapsed":381,"user":{"displayName":"23522009 Farrel Satya Putra Mahendra","userId":"05920376284151714449"}},"outputId":"de19fac0-9b2d-4f4c-e3c6-23c977f08911"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Label: positive\n","Probability: 0.9998039603233337\n"]}]},{"cell_type":"markdown","source":["It works!"],"metadata":{"id":"B7tOSsrJmwMZ"}}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyMkrTUmpfPXFszQjSub+CqC"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}